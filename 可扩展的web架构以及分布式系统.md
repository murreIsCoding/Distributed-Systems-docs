# Scalable Web Architecture and Distributed Systems  ---Kate Matsudaira
# 可扩展的web架构以及分布式系统
原文地址： [](http://www.aosabook.org/en/distsys.html#fig.distsys.1)

开源软件已经成为许多大型网站的基本构成部分。并且随着网站的发展，这些网站使用的架构开始浮现出一些最佳实践和指导原则。这一章节试图涵盖设计这些大型网站时出现的关键问题，以及为了达到这些目标需要的基本构成部分。

## 1.1分布式系统设计的原则
构建和维护一个可扩展的网站或者应用到底意味着什么？在原始的层面看，我们通过因特网使用户和远程资源连接——具有可拓展性的部分在于资源（或者访问资源的通道），这部分被分布在多个服务器上。  
就像生活中的许多事情一样，开始建设网站之前花些时间提前计划是长远有益的；去了解一些大型网站背后所做的考虑和权衡将使你再构建小型网站时也做出更优的决定。下面是几个影响大规模web系统设计的关键原则：  
* **高可用性** :一个网站的正常运行是许多公司名声和功能的关键。对于一些网络零售网站来说，几分钟的不可用可能会造成成千上万美元的收入损失，因此，将他们的系统设计得高可用以及失败可恢复，是一项基本业务也是技术要求。要实现分布式系统的高可用性，就需要对关键组件的冗余，对局部系统错误事件能快速响应并修复，
以及当问题发生时能够优雅地降级功能，这几方面都需要考虑
* **性能** : 对所有网站来说网页性能也变得越来越被关心。网站的速度影响使用和用户满意度，以及搜索引擎的排名，这都是直接影响收入和用户留存率的因素。所以，创建一个被优化得可以快速响应以及低延迟的系统是很关键的。  
* **可靠性** : 系统需要是可靠的，例如对某个数据的请求将一致性地返回相同的结果。当数据发生改变或者更新的动作，则该请求返回新的数据。用户需要确保一旦数据被写入或存入系统，它将被持久化，并且在后面的检索中可以可靠地查出。
* **可扩展性** : 对于大部分分布式系统来说，规模只是伸缩性考虑的一部分。同样重要的是，系统是否具有在需要增加性能以应对更大量的负载时的扩展能力，即通常所说系统的可扩展性。可扩展性可以参考系统的几个参数：可以处理多少额外增加的流量?增加更多存储能力时
容易吗？可以处理多少事务？
* **可维护性** ： 另外一个关注点是，运维一个系统比开发一个系统难。系统的可维护性等同于操作的可伸缩性：维护和更新。可管理性要考虑的事情是问题发生时是否易于诊断和理解，易于更新或修改以及系统操作是否简单。（即，它是否可以正常运行而不会出现故障或异常？）
* **成本**：成本是一个重要因素。显然，这可能包括硬件和软件成本，但考虑部署和维护系统所需的其他方面也很重要。系统需要花费的开发人员时间，运行系统所需的操作量以及所需的培训量都应考虑在内。成本是总拥有成本。  这些原则中的每一个都为设计分布式Web体系结构中的决策提供了基础。但是，它们也可能彼此矛盾，以至于要实现一个目标就要付出另一个目标的代价。一个基本示例：选择通过简单地添加更多服务器来解决容量问题（可扩展性）可能是以可拓展性（您必须操作一台额外的服务器）和成本（服务器的价格）为代价的。  

## 1.2 基础知识Basic
  当涉及到系统架构时，有几点需要考虑：什么是正确的部分，这些部分如何组合在一起配合，以及什么是正确的权衡，在必须具有扩展性之前就投资大量时间通常不是一个明智的业务主张。但是，对设计进行一些预先设计的确可以在将来节省大量的时间和资本。本节重点关注大型网站应用至关重要的一些核心因素：服务(Service)，冗余(redundancy)，分区(partitions)，故障处理(handing failure)。这些因素每一个都涉及一些选择和妥协，尤其是在上一节提到的相关原则。为了详细解释这些，最好从一个例子开始。
### 实例：图片托管网站
你也许曾在网上po过照片。对于这种托管和分发大量图像的大型网站来说，构建高性价比、高可用性、低延迟(快速检索)的系统架构是非常具有挑战性的。  想象一下Flickr或Picasa网，用户通过请求一个web地址或者api来从中心服务器上传下载图片。为了简单起见，让我们假定此应用程序具有两个关键部分：将图像上传（写入）到服务器的能力以及查询图像的能力。尽管我们当然也希望上传效率高，但是我们最最关心还是在有人请求图像时（例如，可以为网页或其他应用程序请求图像）非常快速地响应。这是一个web服务或CDN（Content Delivery Network）边缘计算(服务器CDN用于将内容存储在许多位置，因此内容在地理/物理上更接近用户，从而提高了性能)来提供。该系统其他重要方面：
* 对要存储的图像数量没有限制，因此需要考虑图片数量方面的存储的可伸缩性。
* 图像下载/请求的等待时间必须短。
* 如果用户上传图像，则该图像应始终存在（图像的数据可靠性）。
* 该系统应易于维护（可维护性）。
* 由于图像托管的利润率不高，因此该系统必须具有高性价比。  
图1.1是功能的简化图
![图1.1：图像托管应用程序的简化架构图](http://www.aosabook.org/images/distsys/imageHosting1.jpg)  
在这个实例中，这个系统必须快速响应，数据存储可靠并且这些属性都具有高扩展性。在一个单服务器上构建一个简单版本的程序时非常琐碎又简单的事情。不在本文章的讨论范围中。让我们假设我们将建造可能会发展成Flickr一样大型的应用。  
### 服务(Services)
对于可扩展性系统设计，有助于分离功能点，并通过定义清晰的接口使系统的每个部分成为一个服务。实际上，这种系统设计被称为SOA(Service-Oriented Architecture面向服务架构).这种类型的系统，每个服务有它自身特定的功能上下文，并且通过抽象接口(通常是公共API或者其他服务)来与外部交互。  

将系统解构成一组互补的服务使得每个组件的操作彼此分离。这种抽象有助于在服务、底层环境、服务的消费者之间建立清晰的关系脉络。创建这些清晰的轮廓图可以帮助独立每个问题，也使得每个组件可以独立地扩展。这种系统的面向服务有点类似于编程时的面向对象设计。
  
  在刚才的实例中，所有查询和上传的请求都是由相同的服务来处理。但是，由于系统需要扩展，这个服务需要被分开成2个单独的服务。  

快进并假设该服务已大量使用；这样的场景使您很容易看到写入时间会影响读取图像的时间（因为这两个功能将争夺共享资源）。根据架构的不同，这种影响可能很大。即使上载和下载速度相同（对于大多数IP网络而言，事实并非如此，因为大多数IP网络是为至少3：1的下载速度：上载速度的比率而设计的），读取的文件通常也会从缓存中读取，但写入数据最终将不得不将数据写入磁盘（并且在最终一致的情况下可能要写入多次）。即使所有内容都在内存中或从磁盘（如SSD）读取，数据库写入几乎总是比读取慢。（Pole Position，一个用于DB基准测试的开源工具，<http://polepos.org>，结果<http://polepos.sourceforge.net/results/PolePositionClientServer.pdf>)  

这种设计的另一个潜在问题是，像Apache或lighttpd这样的Web服务器通常对其可以保持的同时连接数有一个上限（默认值约为500，但可能更高），并且在高流量中，写入会很快消耗掉所有这些。由于读取可以是异步的，也可以利用其他性能优化（例如gzip压缩或分块传输编码）的优势，因此Web服务器可以更快地切换服务读取，并可以在客户端之间快速切换，
以每秒服务的请求数量超过最大连接数（使用Apache和最大连接数设置为500，通常每秒可处理数千个读取请求）。另一方面，写入操作会在上载期间保持开放连接，因此在大多数家庭网络上载1MB的文件可能会花费超过1秒的时间，因此Web服务器只能处理500个此类同时写入。  
![读写分离](http://www.aosabook.org/images/distsys/imageHosting2.png)  

通过将图像的读写分为各自的服务来解决瓶颈的一个好案例，如图1.2所示。这使我们能够独立地伸缩它们中的其中一个（因为我们可能总是有更多的读取而不是写作），而且还有助于弄清每部分到底在发生什么。最后，这将未来的顾虑分开，这将使故障排除和解决问题（例如读取速度慢）更加容易。  

这种实现的优势在于，我们能够彼此独立地解决问题-我们不必担心在同一上下文中写入和检索新图像。这两种服务仍然可以利用全局图片仓库，但是它们可以使用适合服务的方法独立地优化自身性能（例如，排队请求或缓存受欢迎的图像，有关更多信息，请参见下文）。从维护和成本的角度来看，每个服务都可以根据需要独立扩展，这非常好，因为如果将它们组合并混合在一起，则一个服务可能会无意中影响另一个服务的性能，如上面所讨论的情形。  

当然，当您有两个不同的端点时，上面的示例也可以很好地工作（实际上，这与一些云存储提供商的实现和内容交付网络非常相似）。但是，有很多方法可以解决这种类型的瓶颈，并且每种方法都有不同的权衡。  

比如，Flickr会分发用户到不同的分片，使得每个分片可以只处理一部分的用户请求，随着用户的增加，集群将增加更多的分片，以此来解决读/写的问题(参见Flickr扩展性的相关描述 []( http://mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html) )。在第一个示例中，更容易根据实际使用量（整个系统的读写次数）来扩展硬件，而Flickr随其用户群进行扩展（但会强制假设整个用户的使用量相同，因此可能会有额外的容量））。在前一种情况下，其中一项服务发生故障或出现问题会降低整个系统的功能（例如，没有人可以写入文件），而使用Flickr碎片之一发生的中断只会影响这些用户。在第一个示例中，更容易在整个数据集中执行操作（例如，更新写服务以包括新的元数据或在所有图像元数据中进行搜索），而使用Flickr架构，则需要更新或搜索每个分片（或需要创建搜索服务来整理该元数据（实际上它们就是这么做的）。

对于这些系统，没有正确的答案，但是可以帮助您回到本章开始的原则，确定系统需求（大量读写操作，并发级别，跨数据集的查询，范围，排序等），对不同的替代方案进行基准测试，了解系统将如何发生故障，并为发生故障的时候制定可靠的计划。

### 冗余Redundancy
为了优雅地处理故障，Web体系结构必须具有其服务和数据的冗余。例如，如果在单个服务器上仅存储一个文件的副本，则丢失该服务器意味着丢失该文件。丢失数据很少是一件好事，处理这种问题的常见方法是创建多个或冗余的副本。

同样的原则也适用于服务。如果应用程序具有核心功能，则确保同时运行多个副本或版本可以防止单个节点发生故障。

在系统中创建冗余可以消除单点故障，并在危机出现时提供备份或备用功能。例如，如果生产中正在运行同一服务的两个实例，而一个实例发生故障或降级，则系统可以故障转移到正常副本。故障转移可以自动发生也可以手动干预。

服务冗余的另一个关键部分是创建无共享架构。通过这种体系结构，每个节点都能够彼此独立地操作，并且没有中央“大脑”管理其他节点的状态或协调活动。由于可以在没有特殊条件或信息的情况下添加新节点，因此对可伸缩性大有帮助。但是，最重要的是，这些系统中没有单点故障，因此它们对故障具有更大的弹性。

例如，在我们的图像服务器应用程序中，所有图像将在某处的另一块硬件上具有冗余副本（如果发生灾难，例如在数据中心发生地震或火灾，最好在不同的地理位置），并提供并且访问这些图像的所有服务也是有冗余的，所有潜在的服务都处理着请求。（请参阅图1.3。）（负载均衡器是实现此目标的好方法，但更多内容下面再讲）。
![图1.3 具有冗余的图像托管应用程序](http://www.aosabook.org/images/distsys/imageHosting3.png)

### 分片
非常大的数据集无法容纳在单个服务器上。另外如果一个操作需要太多的计算资源，导致降低了性能而必须增加容量。无论哪种情况，您都有两种选择：垂直伸缩或水平伸缩。  
纵向扩展意味着向单个服务器添加更多资源。因此，对于非常大的数据集，这可能意味着添加更多（或更大）的硬盘驱动器，以便单个服务器可以包含整个数据集。对于计算操作，这可能意味着将计算移动到具有更快CPU或更多内存的更大服务器上。对于这些情况下，垂直扩展都是通过使单个资源能够自行处理更多资源来实现的。

另一方面，水平缩放就是添加更多节点。对于数据资源，可能会利用另外一台服务器来存储部分数据集，对于计算资源而言，这意味着将操作拆分或分配给其他节点。为了充分利用水平缩放，应将其作为系统体系结构的固有设计原则包括在内，否则修改和分离上下文以使其变得非常笨重。  
当涉及到水平扩展时，较常见的技术之一是将服务分为多个分区或碎片。可以分布分区，以使每个逻辑功能集都是独立的。这可以通过地理边界来完成，也可以通过其他标准（例如非付费用户还是付费用户）来完成。这些方案的优点是他们通过增加额外的能力来提供服务或数据存储。  
在我们的图像服务器示例中，用于存储图像的单个文件服务器可能被多个文件服务器代替，每个文件服务器都包含自己的唯一图片集。（请参见图1.4。）这样的体系结构将允许系统用图片填充每个文件服务器，并在磁盘已满时增加其他服务器。这种设计将需要一种命名方案，将图片的文件名绑定到包含该文件名的服务器。映像名称可以由服务器的一致哈希方案来生成映射。或者，可以为每个图像分配一个增量ID，以便当客户端请求图像时，图像检索服务仅需要维护映射到每个服务器的ID范围内的请求（如索引）。
![具有冗余和分区的图像托管应用程序](http://www.aosabook.org/images/distsys/imageHosting4.png)

当然，跨多个服务器分布数据和功能也存在挑战。关键问题之一是数据位置。在分布式系统中，数据离操作或计算点越近，系统的性能越好。因此，将数据分布在多个服务器上可能存在问题，因为有些时候它可能都不是本地的，从而迫使服务器在网络上执行所需信息获取，造成昂贵的花费(时间或流量)。

另一个潜在的问题是不一致的情况。当从共享资源（可能是另一个服务或数据存储）中读取和写入不同的服务时，则有可能出现竞态（本来应该更新某些数据，但读取发生在更新之前），在这种情况下发生数据不一致。例如，在图像托管方案中，如果一个客户端发送了使用新标题更新”狗“图像的请求，将其从“ Dog”更改为“ Gizmo”，则可能发生竞争情况，但与此同时，另一位客户端正在读取图片。在这种情况下，没办法清楚第二个客户收到的标题是“Dog”还是“ Gizmo”。

数据分区必然存在一些障碍，但是分区允许将每个问题（按数据，负载，使用模式等）拆分为可管理的块。这可以帮助实现可伸缩性和可管理性，但并非没有风险。有很多减轻风险和处理故障的方法。但是，为了简洁起见，本章未介绍它们。如果您有兴趣阅读更多内容，可以查看我的有关容错和监视的博客文章。

## 构建快速和可扩展的数据访问的基础
涵盖了设计分布式系统时的一些核心考虑因素后，现在让我们讨论最困难的部分：扩展对数据的访问。  
大多数简单的Web应用程序（例如LAMP堆栈应用程序） 如图1.5所示。  
![图1.5：简单的Web应用程序](http://www.aosabook.org/images/distsys/simpleWeb.png)  
随着它们的增长，存在两个主要挑战：扩展对应用程序服务器和数据库的访问。在高度可扩展的应用程序设计中，通常将应用程序（或Web）服务器最小化，并且通常体现为无共享架构。这使得系统的应用服务器层可以水平扩展。这种设计的结果是，繁重的工作被堆积到数据库服务器和支持服务。在这一层，真正的扩展性和性能方面的挑战开始出现。  
本章的其余部分专门介绍一些较常见的策略和方法，通过提供对数据的快速访问来使这些类型的服务快速且可扩展。  
![图1.6：充分简化的Web应用程序](http://www.aosabook.org/images/distsys/overSimpleWeb.png)  
大多数系统可以简化为图1.6。这是一个很好的起点。如果您有大量数据，则需要快速轻松地访问，例如将糖果藏在办公桌的顶部抽屉中。尽管过分简化，但先前的说明提示我们两个难题：存储的可伸缩性和数据的快速访问。  
在本节中，我们假设您有许多TB的数据，并且希望允许用户随机访问该数据的一小部分。（请参见图1.7。）这类似于在前面的图像应用程序示例中将图像文件放置在文件服务器上的某个位置。 ![图1.7：访问特定数据](http://www.aosabook.org/images/distsys/accessingData.png)

这特别具有挑战性，因为将TB的数据加载到内存可能会非常昂贵。这直接转换为磁盘IO。从磁盘读取比从内存读取慢许多倍——内存访问的速度与Chuck Norris(一个动作片明星，和李小龙合演过《猛龙过江》)一样快，而磁盘访问的速度比在车管所排队的速度慢。这种速度差异确实会增加大型数据集。在真实数据中，顺序读取的内存访问速度比从磁盘读取的速度快6倍，而随机读取速度则快100,000倍（请参见“大数据的病症”， []( http://queue.acm.org/detail.cfm?id=1563874) ）。而且，即使具有唯一的ID，解决知道在哪里找到少量数据的问题也是一项艰巨的任务。就像试图蒙住眼睛从糖果盒中获取最后的Jolly Rancher(一种糖果)一样。

值得庆幸的是，您有许多选择来解决这些问题。较重要的四个是：**高速缓存，代理，索引和负载均衡**。本节的其余部分讨论如何分别使用这些概念中来使数据访问快得多。

### 缓存Caches
缓存利用了这一点参考原则：最近请求的数据很有可能会再次被请求。它们几乎用于计算的每个层次：硬件， 缓存利用了这一点参考原则：最近请求的数据很有可能会再次被请求。它们几乎用于计算的每个层次：硬件，操作系统，Web浏览器，Web应用程序等等。高速缓存就像一种短期的内存：它具有有限的空间量，但是通常比原始数据源快，并且包含最近访问的项目。缓存可以存在于体系结构的所有层级，但通常位于最接近前端的层级，即在能够实现不增加下游级别负担的情况下快速返回数据的地方。操作系统，Web浏览器，Web应用程序等等。高速缓存就像一种短期的内存：它具有有限的空间量，但是通常比原始数据源快，并且包含最近访问的项目。缓存可以存在于体系结构的所有层级，但通常位于最接近前端的层级，即在能够实现不增加下游级别负担的情况下快速返回数据的地方。

在我们前面的API DEMO中，如何使用缓存来使您的数据访问更快？在这种情况下，您可以在几个地方插入缓存。一种选择是在请求层节点上插入缓存，如图1.8所示。
![图1.8：在请求层节点上插入缓存](http://www.aosabook.org/images/distsys/cache.png)

将缓存直接放置在请求层节点上可以实现响应数据的本地存储。每次对服务提出请求时，该节点将快速返回本地缓存的数据（如果存在）。如果它不在高速缓存中，则请求节点将从磁盘查询数据。一个请求层节点上的缓存还可以位于内存中（这非常快）和位于节点的本地磁盘上（比进入网络存储要快）。

将其扩展到许多节点的情况时会发生什么？如图1.9所示，如果将请求层扩展到多个节点，则仍然有可能让每个节点托管自己的缓存。但是，如果您的负载均衡器在节点之间随机分配请求，则相同的请求将到达不同的节点，从而增加了缓存丢失率。解决这个问题的两个选择是全局缓存和分布式缓存。

![图1.9：多个缓存](http://www.aosabook.org/images/distsys/multipleCaches.png)

### 全局缓存Global Cache

就像它的字面意思一样：所有节点都使用一个相同缓存空间。这涉及添加服务器或某种文件存储，比原始存储更快的速度并且可供所有请求层节点访问。查询缓存的方式与本地缓存的方式相同。这种缓存方案可能会变得有些复杂，因为随着客户端和请求数量的增加，很容易使单个缓存不堪重负，但是在某些架构（尤其是那些具有专用硬件的架构中非常有效，或需要缓存的是固定的数据集，这将使得全局缓存非常高校）。

图中描绘了两种常见形式的全局缓存。在图1.10中，当在缓存中找不到缓存的响应时，缓存本身将负责从基础存储中检索丢失的数据。在图1.11中，请求节点负责检索在缓存中找不到的任何数据。

![图1.10：全局缓存，其中缓存负责检索](http://www.aosabook.org/images/distsys/globalCache1.png)  
![图1.11：全局缓存，其中请求节点负责检索](http://www.aosabook.org/images/distsys/globalCache2.png)

利用全局高速缓存的大多数应用程序倾向于使用第一种类型，其中高速缓存本身负责管理逐出和获取数据，以防止来自客户端的对相同数据的请求泛滥。但是，在某些情况下，第二种实现更有意义。例如，如果高速缓存用于非常大的文件，则较低的高速缓存命中百分比将导致高速缓存缓冲区因高速缓存未命中而变得不堪重负；在这种情况下，在缓存中拥有总数据集（或热数据集）的很大一部分是比较有意义的。另一个例子是一种架构，其中存储在缓存中的文件是静态的，不应被驱逐。（这可能是因为应用程序对该数据有低延迟的需求-某些数据对于大型数据集可能需要非常快-也就是说应用程序逻辑比高速缓存本身更加清楚什么是该逐出的什么是该缓存的热点数据）。

### 分布式缓存
在分布式缓存中（图1.12），每个节点都拥有部分缓存数据，因此，如果把缓存比喻为杂货店里的冰箱，那么分布式缓存就像将食物放在多个位置（冰箱，橱柜，便当盒和无需前往商店即可从中取得小吃的方便位置。通常，使用一致的哈希函数对高速缓存进行划分，这样，如果请求节点正在查找某个数据，它可以快速知道数据在分布式高速缓存中的位置，以确定该数据是否可达。在这种情况下，每个节点都有一小部分缓存，然后将在发送到原始节点之前向另一个节点发送数据请求。因此，分布式缓存的优点之一是如果需要，通过将添加节点到请求池即可增加缓存空间。

分布式缓存的一个缺点是补救丢失的节点。一些分布式缓存通过在不同节点上存储数据的多个副本来解决此问题。但是，您可以想象这种逻辑将可能迅速变得复杂，尤其是当您从请求层添加或删除节点时。尽管即使一个节点消失并且部分缓存丢失，请求也只会从源中拉出，因此算不上是灾难性的缺点。
[图1.12：分布式缓存](http://www.aosabook.org/images/distsys/distributedCaching.png)

缓存的妙处在于，它们通常可使处理速度更快（当然，在正确实现的情况下！）。你选择的方案使得你可以更快地处理更多请求。但是，所有这些缓存都以必须维护额外的存储空间为代价，通常需要存储在昂贵的内存中。没有什么是免费的。高速缓存对于整体运行速度更快而言非常有用，而且可以在高负载条件下提供系统功能，否则将导致服务完全降级。

其中流行的开源缓存有Memcached（http://memcached.org/）（它既可以用作本地缓存，也可以用作分布式缓存）。但是，还有许多其他选项（包括许多特定语言或框架的选项）。

Memcached已在许多大型网站中使用，尽管它看起来非常强大，其实只是一种运行在内存中的针对任意数据存储和快速查找进行了优化的键值存储应用。

Facebook使用几种不同类型的缓存来获取其网站性能（请参阅“ [ Facebook缓存和性能](http://sizzo.org/talks/) ”）。他们在语言级别使用$GLOBALS和APC缓存（在PHP中以函数提供调用），这有助于进行中间函数调用，并且结果更快。（大多数语言都具有这些类型的库来改善网页性能，因此应多使用它们。）然后，Facebook使用分布在许多服务器上的全局缓存（请参阅 [“在Facebook上缩放内存缓存”](http://www.facebook.com/note.php?note_id=39391378919) ），这样一个函数调用访问缓存可以并行发出许多请求，以请求存储在不同Memcached服务器上的数据。这使他们可以在获取用户配置文件数据时得到更高的性能和吞吐量，并且可以在一个中心位置更新数据（这很重要，因为在运行数千台服务器时，缓存丢弃和保持一致性可能是一个巨大的挑战。）

现在让我们谈谈当数据不在缓存中时该怎么办……

## 代理Proxies
在基本层面上看，代理服务器是硬件/软件的中间件，用于接收来自客户端的请求并将其中继到后端源服务器。通常，代理用作过滤请求、记录请求日志或转换请求（通过添加/删除headers，加密/解密 或 压缩）。
![图1.13：代理服务器](http://www.aosabook.org/images/distsys/proxies.png)

当协调来自多台服务器的请求时，代理也非常有用，可以从系统范围的角度优化请求流量。使用代理加速数据访问的一种方式是将相同（或相似）的请求折叠成一个请求，然后将单个结果返回给发出请求的客户端。这称为合并转发（ collapsed forwarding）。

想象一下，通过几个节点请求一个相同的数据（我们称其为littleB），并且该数据不在缓存中。如果该请求通过代理路由，这些请求将被折叠为一个，这意味着我们只需要从磁盘读取littleB一次。（请参见图1.14。）此设计会带来一些成本，因为每个请求的等待时间可能会稍长一些，并且某些请求可能会稍有延迟以将相似的请求分组。但是，它将提高高负载情况下的性能，尤其是当一遍又一遍地请求相同的数据时。这类似于缓存，但是与缓存存储数据/文档的形式不同，它时优化对这些文档的请求或调用，就像充当这些客户端的代理。

例如，在LAN代理中，客户端不需要其自己的IP即可连接到Internet，并且LAN将合并来自客户端的相同内容的呼叫。但是，由于许多代理服务器也是高速缓存（这是放置高速缓存的非常合逻辑的地方），因此在这里很容易混淆，但是并非所有高速缓存都充当代理。

![图1.14：使用代理服务器合并请求](http://www.aosabook.org/images/distsys/collapseRequests.png)

使用代理的另一种方式是不仅折叠对相同数据的请求，而且折叠对原始存储区（连续在磁盘上）在空间上靠近的数据的请求。采用这种策略可以最大程度地提高请求的数据局部性，从而可以减少请求等待时间。例如，假设一堆节点请求B的部分：partB1，partB2等。我们可以设置代理以识别出每个请求的空间位置，将它们合并成单个请求并仅返回bigB，从而极大地减少了从数据源读取。（请参见图1.15。）当您随机访问TB级的数据时，这可能在请求时间上有很大的不同！代理可以在高负载情况下或缓存有限时特别有用，因为它们实际上可以将多个请求批量处理为一个。
![图1.15：使用代理合并空间上靠近的数据请求](http://www.aosabook.org/images/distsys/collapseRequestsSpatial.png)

值得注意的是，可以将代理和缓存一起使用，但是通常最好将缓存放在代理服务器的前面，出于同样的原因，即最好让速度更快的跑步者在拥挤的马拉松比赛中首先开始。这是因为高速缓存从内存中提供数据，它非常快，并且它不介意针对相同结果的多个请求。但是，如果缓存位于代理服务器的另一端，则缓存之前的每个请求都会有额外的延迟，这可能会降低性能。

如果您正在考虑向系统中添加代理，则可以考虑许多选项。 Squid和Varnish都经过了负载测试，并广泛用于许多生产网站。这些代理解决方案提供了许多优化功能，以充分利用客户端与服务器之间的通信。在Web服务器层上安装其中之一作为反向代理（在下面的负载均衡器部分中有说明）可以大大提高Web服务器的性能，从而减少处理传入的客户端请求所需的工作量。

## 索引Indexes
使用索引快速访问数据是优化数据访问性能的众所周知的策略。在数据库层面使用可能是最为熟知的。索引需要权衡增加的存储开销和较慢的写入速度（因为必须同时写入数据和更新索引），以利 于更快的读取速度。

就像传统的关系数据存储一样，您也可以将此概念应用于更大的数据集。使用索引的诀窍是您必须仔细考虑用户如何访问您的数据。如果数据集的大小为许多TB，但有效载荷(数据)很小（例如1 KB），则索引是优化数据访问的必要条件。在如此大的数据集中找到较小的有效载荷(数据)可能是一个真正的挑战，因为您不可能在任何合理的时间内对这么多的数据进行遍历查找。此外，如此大的数据集很可能分布在几个（或多个！）物理设备上-这意味着您需要某种方式来找到所需数据的正确物理位置。索引是执行此操作的最佳方法。  
![图1.16：索引](http://www.aosabook.org/images/distsys/indexes.jpg)

索引可以像目录一样使用，将您定向到数据所在的位置。例如，假设您正在寻找一段数据，即B的第2部分-您将如何知道在哪里找到它？如果您有一个按数据类型排序的索引（例如数据A，B，C），它将告诉您数据B在原点的位置。然后，您只需要寻找该位置并阅读所需的B部分即可。（请参见图1.16。）

这些索引通常存储在内存中，或者非常靠近接受客户请求的地方。伯克利DB（BDB）和树状数据结构通常将数据存储在有序列表中，这非常适合利用索引进行访问。

通常，有许多层索引用作地图，将您从一个位置移动到另一位置，依此类推，直到获得所需的特定数据为止。（参见图1.17。）

索引也可以用于创建同一数据的多个不同视图。对于大型数据集，这是一种定义不同过滤器和排序的方式，而不需要依靠创建许多其他数据副本来实现。

例如，假设以前的图像托管系统实际上是托管书籍页面的图像，并且该服务允许客户查询这些图像中的文本，搜索有关某个主题的所有书籍内容，搜索引擎可以使您搜索HTML内容。在这种情况下，所有这些书籍图像都需要许多服务器来存储文件，并且找到一页要呈现给用户的内容可能会有些麻烦。首先，用于查询任意单词和单词元组的逆索引(倒排索引)必须易于访问；那么就面临着导航到该书中确切的页面和位置并为结果检索正确图像的挑战。因此，在这种情况下，倒排索引将映射到一个位置（例如书B），然后图书B可能包含一个索引，其中包含每个部分中的所有单词，位置和出现次数。  
上图中index1可能看起来类似于以下内容-每个单词或单词元组提供了包含哪些书籍的索引。

| Word(s)       | Book(s)                |
|:--------------|:-----------------------|
| being awesome | Book B, Book C, Book D |
| always        | Book C, Book F         |
| believe       | Book B                 |

这在大型系统中很关键，因为即使压缩，这些索引也可能变得相当大且存储昂贵。在这个系统中，如果我们假设世界上有很多图书-100,000,000（请参阅 [Google图书内部](http://booksearch.blogspot.com/2010/08/books-of-world-stand-up-and-be-counted.html) ），并且每本书只有10页长（为了简化数量），每页250个单词，这意味着有2500亿字。如果我们假设每个单词平均5个字符，并且每个字符占用8位（或1个字节，即使某些字符为2个字节），那么每个单词5个字节，那么仅包含每个单词一次的索引就超过了TB的TB。存储。因此，你会发现创建包含其他信息（例如单词元组，数据位置和出现次数）的索引的过程会比较迅速。

创建这些中间索引并在较小的部分中表示数据可以使大数据问题变得易于处理。数据可以分布在许多服务器上，并且仍然可以快速访问。索引是信息检索的基石，也是当今现代搜索引擎的基础。当然，本节仅涉及表面知识，并且正在进行许多有关如何使索引更小，更快，包含更多信息（如相关性）以及无缝更新的研究。（竞争条件以及添加新数据或更改现有数据所需的大量更新都存在一些可管理性挑战，尤其是在涉及相关性或计分的情况下）。

能够快速轻松地找到您的数据很重要；索引是实现此目标的有效且简单的工具。

### 负载均衡器 LoadBalance
最后，任何分布式系统的另一个关键部分是负载均衡器。负载平衡器是任何体系结构的主要组成部分，因为它们的作用是在负责服务请求的一组节点之间分配负载。它允许多个节点透明地提供相同的功能。（请参见图1.18。）它们的主要目的是处理大量同时连接，并将这些连接路由到请求节点之一，从而允许系统仅通过添加节点即可扩展以服务更多请求。  
![图1.18：负载平衡](http://www.aosabook.org/images/distsys/loadBalancer.png)

有许多不同的算法可用于处理请求，包括选择随机节点，循环轮询，甚至根据某些标准（例如内存或CPU利用率）选择节点。负载均衡器可以是软件或硬件设备形式。HAProxy是一种已被广泛采用的开源软件负载平衡器。

在分布式系统中，负载平衡器通常位于系统的最前端，因此所有传入的请求都会相应地路由。在复杂的分布式系统中，将请求路由到多个负载均衡器也是很常见的，如图1.19所示。  
![图1.19：多个负载均衡器](http://www.aosabook.org/images/distsys/multipleLoadBalancers.png)

像代理一样，某些负载平衡器还可以根据请求的类型路由到不同的地方。（从技术上讲，这些也称为反向代理。）

负载平衡器的挑战之一是管理特定用户会话session的数据。在一个电子商务站点中，当您只有一个客户端时，很容易将用户将物品放入购物车中并在下次访问保留这些内容（这很重要，因为如果用户重新登录后商品还在，他很有可能会购买它）。但是，如果将用户路由到一个节点进行会话session，然后在下一次访问时将其路由到另一个节点，则可能会出现不一致，因为新节点可能会丢失该用户的购物车内容。（如果您在购物车中放了6包Mountain Dew，然后又回来却空了，您会不会感到烦恼？）一种解决方法是使会话保持粘性，以便始终将用户路由到同一节点，但是将造成很难利用某些可靠性功能，例如自动故障转移。在这种情况下，用户的购物车将始终具有内容，但是如果他们关联粘性的节点不可用，那将出现特殊情况，即不能保证购物车内容永远存在（尽管应用程序中不希望有这个保证）。当然，可以使用本章中的其他策略和工具来解决此问题，例如服务，以及许多未涵盖的内容（例如浏览器缓存，cookie和URL重写）。

如果系统只有几个节点，则循环DNS之类的系统可能更有意义，因为负载均衡器可能很昂贵，并且会增加不必要的复杂性。当然，在较大的系统中，存在各种不同的调度和负载平衡算法，包括简单的算法（例如随机选择或轮询），以及更复杂的机制，其中要考虑利用率和容量。所有这些算法都允许分发流量和请求，并可以提供有用的可靠性工具，例如自动故障转移或自动删除不良节点（例如，当它变得无响应时）。但是，这些高级功能会使问题诊断变得麻烦。例如，当涉及到高负载情况时，负载平衡器将删除速度较慢或超时（由于请求过多）的节点，但这只会加剧其他节点的情况。在这些情况下，广泛的监视非常重要，因为整个系统的流量和吞吐量可能看起来正在下降（因为节点为更少的请求提供服务），但各个节点却变得越来越繁忙。

负载平衡器是一种允许您扩展系统容量的简便方法，并且与本文中的其他技术一样，它在分布式系统体系结构中也起着至关重要的作用。负载平衡器还提供了一项重要功能，即能够测试节点的运行状况，如果节点无响应或过载，则可以从请求池中删除，而去使用系统中其他的冗余节点。